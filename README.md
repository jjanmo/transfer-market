# Crawling & Data Analysis

> [í•´ë‹¹ ê°•ì˜](https://www.inflearn.com/course/%EC%9B%B9%ED%81%AC%EB%A1%A4%EB%A7%81-%EC%B6%95%EA%B5%AC%EC%84%A0%EC%88%98%EB%B6%84%EC%84%9D#) ë¥¼ í†µí•´ì„œ í¬ë¡¤ë§ê³¼ ë°ì´í„° ë¶„ì„ì— ëŒ€í•œ ë§›ë³´ê¸° ì‹¤ìŠµ ğŸ¥³

> BeautifulSoup, Pandasì— ëŒ€í•œ ì‚¬ìš©ë²•ì„ ì•Œì•„ë³´ì ğŸš€


## ì•Œì•„ë‘¬ì•¼ í•  ê²ƒë“¤

### Web Scraping vs Web Crawling

- ì›¹ ìŠ¤í¬ë˜í•‘ : ì›¹ ì‚¬ì´íŠ¸ ìƒì—ì„œ ì›í•˜ëŠ” ë¶€ë¶„ì— ìœ„ì¹˜í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ìˆ˜ì§‘í•˜ëŠ” ê¸°ìˆ 

- ì›¹ í¬ë¡¤ë§ : ìë™í™” ë´‡ì¸ ì›¹ í¬ë¡¤ëŸ¬ê°€ ì •í•´ì§„ ê·œì¹™ì— ë”°ë¼ì„œ ë³µìˆ˜ì˜ ì›¹ í˜ì´ì§€ë¥¼ ë¸Œë¼ìš°ì§• í•˜ëŠ” í–‰ìœ„
 
> ì¼ë°˜ì ìœ¼ë¡œ ë§í•˜ëŠ” ì›¹ í¬ë¡¤ë§ì€ ì›¹ ìŠ¤í¬ë˜í•‘ê³¼ <u>ë™ì¼í•œ ì˜ë¯¸</u>ë¡œ ì“°ì¸ë‹¤.

### ë¡œë´‡ ë°°ì œ í‘œì¤€(Robots exclusion protocol)

ì›¹ ì‚¬ì´íŠ¸ì— ë¡œë´‡ì´ ì ‘ê·¼í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ê·œì•½ (ê¶Œê³ ì•ˆ)ìœ¼ë¡œ ì¼ë°˜ì ìœ¼ë¡œ ì ‘ê·¼ ì œí•œì— ëŒ€í•œ ì„¤ëª…ì€ ê° ì‚¬ì´íŠ¸ë§ˆë‹¤ `robots.txt`ì— ê¸°ìˆ ë˜ì–´ ìˆë‹¤.
`https:// [ì‚¬ì´íŠ¸ëª…] /robots.txt` ë¡œ ì ‘ê·¼í•˜ë©´ í•´ë‹¹ ë¬¸ì„œë¥¼ ë³¼ ìˆ˜ ìˆë‹¤.


### ì›¹ ë™ì‘ ë°©ì‹

![web](./images/web.png)


### í¬ë¡¤ë§ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤

> Requests & BeautifulSoup

- [Requests](https://docs.python-requests.org/en/master/) 

- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)

### Pandasì˜ ê¸°ë³¸ì ì¸ ì‚¬ìš©ë²•

- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)

![pandas1](./images/pandas1.png)

![pandas2](./images/pandas2.png)

